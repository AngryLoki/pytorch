name: pull

on:
  pull_request:
    branches-ignore:
      - nightly
  push:
    branches:
      - main
      - release/*
      - landchecks/*
  workflow_dispatch:
  schedule:
    - cron: 29 8 * * *  # about 1:29am PDT

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: true

permissions: read-all

jobs:
  llm-td:
    name: before-test
    uses: ./.github/workflows/llm_td_retrieval.yml
    permissions:
      id-token: write
      contents: read

  target-determination:
    name: before-test
    uses: ./.github/workflows/target_determination.yml
    needs: llm-td
    permissions:
      id-token: write
      contents: read

  linux-jammy-py3_8-gcc11-build:
    name: linux-jammy-py3.8-gcc11
    uses: ./.github/workflows/_linux-build-label.yml
    with:
      build-environment: linux-jammy-py3.8-gcc11
      docker-image-name: pytorch-linux-jammy-py3.8-gcc11
      runner: lf.c.linux.2xlarge
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 3, runner: "linux.2xlarge" },
          { config: "default", shard: 2, num_shards: 3, runner: "linux.2xlarge" },
          { config: "default", shard: 3, num_shards: 3, runner: "linux.2xlarge" },
          { config: "docs_test", shard: 1, num_shards: 1,  runner: "linux.2xlarge" },
          { config: "jit_legacy", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
          { config: "backwards_compat", shard: 1, num_shards: 1, runner: "linux.2xlarge" },
          { config: "distributed", shard: 1, num_shards: 2, runner: "linux.2xlarge" },
        ]}

  win-vs2019-cpu-py3-build:
    # don't run build twice on main
    if: github.event_name == 'pull_request'
    name: win-vs2019-cpu-py3
    uses: ./.github/workflows/_win-build.yml
    with:
      build-environment: win-vs2019-cpu-py3
      cuda-version: cpu
      sync-tag: win-cpu-build
      test-matrix: |
        { include: [
          { config: "default", shard: 1, num_shards: 3, runner: "lf.c.windows.4xlarge.nonephemeral" },
          { config: "default", shard: 2, num_shards: 3, runner: "lf.c.windows.4xlarge.nonephemeral" },
          { config: "default", shard: 3, num_shards: 3, runner: "lf.c.windows.4xlarge.nonephemeral" },
        ]}
